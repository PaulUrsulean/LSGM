{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.abspath(\"/nfs/homedirs/ursulean/project-4/datasets/weather/40000_5_100_2_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, configs, config_indices = np.load(PATH, allow_pickle=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(m, n_examples=2, rand=True):\n",
    "    fig, axarr = plt.subplots(ncols=n_examples, nrows=2, figsize=(30, 10))\n",
    "    indices = range(n_examples) if not rand else np.random.randint(0, len(data), size=(n_examples))\n",
    "    for i, index in enumerate(indices):\n",
    "        for atom_i in range(m.shape[1]):\n",
    "            axarr[0, i].plot(m[index, atom_i, :, 0])\n",
    "            axarr[1, i].plot(m[index, atom_i, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_values(data, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Avg. temperature distribution\")\n",
    "sns.distplot(data[:, :, :, 0].flatten())\n",
    "plt.figure()\n",
    "plt.title(\"2nd. feature distribution\")\n",
    "sns.distplot(data[:, :, :, 1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temp = data[:, :, :, 0].mean()\n",
    "std_temp = data[:, :, :, 0].std()\n",
    "mean_humid = data[:, :, :, 1].mean()\n",
    "std_humid = data[:, :, :, 1].std()\n",
    "\n",
    "data_norm = data.copy()\n",
    "data_norm[:,:,:,0] = (data_norm[:,:,:,0] - mean_temp) / std_temp\n",
    "data_norm[:,:,:,1] = (data_norm[:,:,:,1] - mean_humid) / std_humid\n",
    "plot_values(data_norm, n_examples=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stations interactions for first Example\")\n",
    "sns.pairplot(pd.DataFrame(data_norm[0, :, :, 0]).swapaxes(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_moving_avg(data, beta=0.3):\n",
    "    smoothed = data.copy()\n",
    "    timesteps = data.shape[2]\n",
    "    for step in range(1, timesteps):\n",
    "        smoothed[:, :, step, :] = beta * data[:, :, step, :] + (1 - beta) * smoothed[:, :, step - 1, :]\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smoothed = exp_moving_avg(data_norm)\n",
    "plot_values(data_smoothed, n_examples=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avg(data, window_size=3):\n",
    "    assert window_size % 2 == 1, \"Only symmetric windows allowed.\"\n",
    "    smoothed = data.copy()\n",
    "    timesteps = data.shape[2]\n",
    "    start_i = window_size // 2\n",
    "    print(f\"Starting at {start_i} with window size {window_size}\")\n",
    "    for step in range(start_i, timesteps - start_i):\n",
    "        val = sum([data[:, :, step - (start_i) + i] for i in range(window_size)]) / window_size\n",
    "        smoothed[:, :, step, :] = val\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asanyarray([[[0.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0]]])\n",
    "x = x[:,:,:,np.newaxis]\n",
    "x_smoothed = moving_avg(x, window_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((moving_avg(data, window_size=1) == data).all())\n",
    "print(not (moving_avg(data, window_size=3) == data).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smoothed = moving_avg(data_norm, window_size=3)\n",
    "plot_values(data_smoothed, n_examples=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smoothed = moving_avg(data_norm, window_size=9)\n",
    "plot_values(data_smoothed, n_examples=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fft, ifft\n",
    "\n",
    "\n",
    "def fft_low_pass(data, percentage_cut=0.2):\n",
    "    smoothed = data.copy()\n",
    "    n_features = data.shape[-1]\n",
    "    n_timesteps = data.shape[-2]\n",
    "    for feat in range(n_features):\n",
    "        data_feat = smoothed[:, :, :, feat]\n",
    "        frequencies = fft(data_feat, axis=-1)\n",
    "        frequencies[:, :, -int(percentage_cut * n_timesteps):] = 0\n",
    "        smoothed[:, :, :, feat] = ifft(frequencies)\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smoothed = fft_low_pass(data_norm, percentage_cut=.85)\n",
    "plot_values(data_smoothed, n_examples=3, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(filename, data):\n",
    "    print(f\"Saving smoothed data under name {filename}\")\n",
    "    np.save(filename, data, allow_pickle=True)\n",
    "\n",
    "def smooth_and_save(path, smoothing_function):\n",
    "    print(f\"Loaded data from path {path}\")\n",
    "    data, configs, configs_i = np.load(path, allow_pickle=True)\n",
    "    \n",
    "    \n",
    "    # Standardize data\n",
    "    mean_temp = data[:, :, :, 0].mean()\n",
    "    std_temp = data[:, :, :, 0].std()\n",
    "    mean_humid = data[:, :, :, 1].mean()\n",
    "    std_humid = data[:, :, :, 1].std()\n",
    "\n",
    "    data_norm = data.copy()\n",
    "    data_norm[:,:,:,0] = (data_norm[:,:,:,0] - mean_temp) / std_temp\n",
    "    data_norm[:,:,:,1] = (data_norm[:,:,:,1] - mean_humid) / std_humid\n",
    "    \n",
    "    # Perform smoothing\n",
    "    print(f\"Smoothing data with {smoothing_function.__name__}\")\n",
    "    data_smoothed = smoothing_function(data_norm)\n",
    "    \n",
    "    new_filename = path.split(\".npy\")[0] + \"_smoothed.npy\" \n",
    "    save_dataset(new_filename, [data_smoothed, configs, configs_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_and_save(PATH, exp_moving_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mllab-venv)",
   "language": "python",
   "name": "mllab-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

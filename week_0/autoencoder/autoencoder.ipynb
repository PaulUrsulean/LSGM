{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Convolutional) Autoencoder on MNIST\n",
    "\n",
    "### Outline\n",
    "1. Feature Preparation\n",
    "2. Model Definition\n",
    "3. Training\n",
    "4. Visual Evaluation (Comparison, t-SNE, ...)\n",
    "5. Generate Plots for different encoding dimensionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the server is using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if using gpu\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "Add new dimension (color channel) to MNIST images and scale to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "X_train = X_train[:,:,:,np.newaxis] / 255.0\n",
    "X_test = X_test[:,:,:,np.newaxis] / 255.0\n",
    "\n",
    "X_val = X_train[50000:]\n",
    "y_val = y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "y_train = y_train[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot random images to check if images were loaded and prepared correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 10)\n",
    "fig.set_size_inches(16, 10)\n",
    "for i, img_index in enumerate(np.random.randint(0, len(X_train), size=(10))):\n",
    "    axis[i].imshow(X_train[img_index].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Flatten, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def build_model(activation='relu', dense_embedding_size=0):\n",
    "    \"\"\" Creates the computation graph for the autoencoder.\n",
    "    Architecture inspired by blog.keras.io/building-autoencoders-in-keras.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    activation: ['relu', 'softmax', 'sigmoid', ...]\n",
    "        Activation function used throughout the network. \n",
    "        See keras.io/activations/ for possible values.\n",
    "    dense_embedding_size: int\n",
    "        If larger than 0, the bottleneck of the autoencoder additionally uses two fully connected layers.\n",
    "        The value specivies the size of the bottleneck-layer. \n",
    "        Otherwise no fully connected layers are used and the bottleneck comprises 4*4*8=128 values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (encoder, decoder): tuple\n",
    "    Two keras.models.Model objects representing the encoder part and the whole autoencoder\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define Computation Graph\n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation=activation, padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation=activation, padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation=activation, padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    encoded = Flatten()(x)\n",
    "    \n",
    "    if dense_embedding_size > 0:\n",
    "        encoded = Dense(dense_embedding_size, activation=activation)(encoded)\n",
    "        x = Dense(128, activation=activation)(encoded)\n",
    "        x = Reshape((4, 4, 8))(x)\n",
    "\n",
    "    x = Conv2D(8, (3, 3), activation=activation, padding='same', input_shape=(4, 4, 8))(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(8, (3, 3), activation=activation, padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation=activation)(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    # Use default parameters of Adam\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    # Define Models\n",
    "    encoder = Model(input_img, encoded)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer=opt, loss='binary_crossentropy', metrics=[])\n",
    "    \n",
    "    return encoder, autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model\n",
    "We now specify a few hyperparameters and create and train our model.  \n",
    "We could also perform e.g. a Grid-Search and parameterize more design choices of our model. For sake of simplicity we don't do this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 40\n",
    "ACTIVATION = 'relu'\n",
    "MAX_EPOCHS = 80\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, autoencoder = build_model(activation=ACTIVATION, dense_embedding_size=EMBED_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(\n",
    "          X_train, \n",
    "          X_train, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=MAX_EPOCHS,\n",
    "          validation_data=(X_val, X_val),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder.evaluate(X_test, X_test, verbose=False)\n",
    "print(\"Loss: %f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, filename=None):\n",
    "    \"\"\" Plot the training and validation loss for each epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history: History\n",
    "        Contains evolution of training and validation loss\n",
    "    filename: string\n",
    "        If not None, additionally saves plot as png\n",
    "    \"\"\"    \n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(history.history['loss'], label='Training Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.legend()\n",
    "    if filename:\n",
    "        plt.savefig(\"Comparison/\" + filename + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def compare_reconstruction(reconstructions, n_images=8, filename=None, indices=None):\n",
    "    \"\"\" Plot a comparison of the network's reconstructions and the original images from the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reconstructions: sequence of images\n",
    "    n_images: int\n",
    "        Number of random images to show\n",
    "    filename: string\n",
    "        If not None, additionally saves plot as png\n",
    "    indices: list\n",
    "        Contains indices of images from the test set, used for visualization.\n",
    "        Set to random values if not specified.\n",
    "    \n",
    "    \"\"\"\n",
    "    %matplotlib inline\n",
    "    if indices is None:\n",
    "        indices = np.random.random_integers(0, 10000, n_images)\n",
    "    \n",
    "    fig, axis = plt.subplots(3, len(indices))\n",
    "    fig.set_size_inches(15, 8)\n",
    "    \n",
    "    for i, img_index in enumerate(indices):\n",
    "        axis[0, i].set_title(\"Original\")\n",
    "        axis[0, i].imshow(X_test[img_index].reshape(28, 28), cmap='gray')\n",
    "        \n",
    "        axis[1, i].set_title(\"Reconstruction\")\n",
    "        axis[1, i].imshow(reconstructions[img_index].reshape(28, 28), cmap='gray')\n",
    "        \n",
    "\n",
    "        tresholded_reconstruction = reconstructions[img_index].reshape(28, 28) > 0.3\n",
    "        tresholded_reconstruction = np.asmatrix(tresholded_reconstruction, dtype=np.float32)\n",
    "        blurred = ndimage.gaussian_filter(tresholded_reconstruction, sigma=.8)\n",
    "        axis[2, i].set_title(\"Thresh/Blur\")\n",
    "        axis[2, i].imshow(blurred, cmap='gray')\n",
    "        \n",
    "    if filename:\n",
    "        fig.savefig(\"Comparison/\" + filename + \".png\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "reconstr = autoencoder.predict(X_test)\n",
    "compare_reconstruction(reconstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualization via t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Calculate encoding for images in test set\n",
    "encodings = encoder.predict(X_test)\n",
    "\n",
    "# CAUTION! Might take several minutes\n",
    "tsne = TSNE(n_components=3, verbose=True)\n",
    "projections = tsne.fit_transform(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "n_samples = 3000\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.setp(ax.get_zticklabels(), visible=False)\n",
    "\n",
    "ax.scatter(projections[:n_samples, 0],\n",
    "           projections[:n_samples, 1],\n",
    "           projections[:n_samples, 2],\n",
    "           c=y_test[:n_samples])\n",
    "\n",
    "def rotate(angle):\n",
    "    ax.view_init(azim=angle)\n",
    "\n",
    "anim = FuncAnimation(fig, rotate, frames=360, interval=60)\n",
    "anim.save('t-SNE_dim_%i.gif' % EMBED_DIM, dpi=80, writer='imagemagick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Autoencoder first\n",
    "with open(\"Models/autoencoder.json\", \"w\") as f:\n",
    "    json = autoencoder.to_json()\n",
    "    f.write(json)\n",
    "\n",
    "# Save Encoder separately. Could be improved to reduce redundancy\n",
    "with open(\"Models/encoder.json\", \"w\") as f:\n",
    "    json = encoder.to_json()\n",
    "    f.write(json)\n",
    "    \n",
    "# Save weights from whole graph\n",
    "autoencoder.save_weights(\"Models/autoencoder_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoencoder when not training from scratch\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "with open(\"Models/autoencoder.json\", \"r\") as f:\n",
    "    autoencoder = model_from_json(f.read())\n",
    "    \n",
    "with open(\"Models/encoder.json\", \"r\") as f:\n",
    "    encoder = model_from_json(f.read())\n",
    "\n",
    "# Load weights\n",
    "autoencoder.load_weights('Models/autoencoder_weights.h5')\n",
    "encoder.load_weights('Models/autoencoder_weights.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare models with different encoding sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [0, 5, 10, 20, 40, 100, 200]\n",
    "i_test_images = np.random.random_integers(0, 10000, 8)\n",
    "\n",
    "for dim in dimensions:\n",
    "    enc, auto = build_model(activation=ACTIVATION, dense_embedding_size=dim)    \n",
    "    history = auto.fit(\n",
    "          X_train, \n",
    "          X_train, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=MAX_EPOCHS,\n",
    "          validation_data=(X_test, X_test),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE)])\n",
    "    \n",
    "    name = \"dim_%i\" % dim\n",
    "    reconstr = auto.predict(X_test)\n",
    "    compare_reconstruction(reconstr, filename=name + \"_reconstruction\", indices=i_test_images)\n",
    "    \n",
    "    loss = auto.evaluate(X_test, X_test, verbose=False)\n",
    "    loss_str = (\"%f\" % np.round(loss, 5)).replace('.', \"_\")\n",
    "    plot_history(history, filename=name + \"_history_loss_\" + loss_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Briefly compare performance of a linear model using encodings vs original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(encoder.predict(X_train), y_train)\n",
    "predictions = clf.predict(encoder.predict(X_test))\n",
    "score = accuracy_score(predictions, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train.reshape(60000, 784), y_train)\n",
    "predictions = clf.predict(X_test.reshape(10000,784))\n",
    "score = accuracy_score(predictions, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencoder_mnist",
   "language": "python",
   "name": "autoencoder_mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
